<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="UTF-8">
    <title>视频生成界面</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style_app.css') }}">
</head>

<body>
    <div class="main-content">
        <div class="left-preview">
            <!-- 音频预览盒子（在视频盒子上方） -->
            <div class="audio-box" style="margin-bottom: 12px;">
                <audio id="previewAudio" class="preview-audio" controls style="width:100%;"></audio>
            </div>
            <div class="video-box">
                <video id="previewVideo" class="preview-video" controls loop style="width:100%; height:auto; background:#000;"></video>
            </div>
        </div>

        <div class="right-form">
            <form method="POST">
                <div class="form-group">
                    <label>模型名称</label>
                    <select>
                        <option>VoicePersona</option>
                    </select>
                </div>

                <div class="form-group">
                    <label>语音克隆模型名称</label>
                    <input type="text" value="Cosy Voice">
                </div>

                <div class="form-group">
                    <label>目标演讲者</label>
                    <select id="targetSpeaker">
                        <option value="obama">Obama</option>
                        <option value="trump">Trump</option>
                        <option value="achu">路人甲</option>
                    </select>
                </div>

                <div class="form-group">
                    <label>参考音频地址</label>
                    <input type="text" id="referenceAudioPath" value="/static/input.wav">
                </div>

                <div class="form-group">
                    <label>目标文字 (文本框)</label>
                    <input type="text" id="inputText" placeholder="请输入目标文本内容...">
                </div>

                <!-- 音频生成与预览相关控件 -->
                <div class="form-group">
                    <label>输出音频地址</label>
                    <input type="text" id="outputWavePath" placeholder="例如：../output/YYMMDD_HHMMSS_output.wav">
                </div>
                <div style="margin-top: 8px; display: flex; gap: 8px;">
                    <button type="button" id="generateAudioBtn" class="submit-btn">利用本机算力生成音频</button>
                    <button type="button" id="generateAudioHuaweiBtn" class="submit-btn">用华为云生成音频</button>
                </div>

                <!-- 视频预览和下一步用到的控件（与音频分离） -->
                <div class="form-group" style="margin-top: 16px;">
                    <label>输出视频地址</label>
                    <input type="text" id="outputVideoPath" placeholder="例如：/media/asset/Obama.mp4 或 /media/output/result.mp4">
                </div>
                <div style="margin-top: 8px; display:flex; gap:8px; align-items:center;">
                    <button type="submit" id="generateBtn" class="submit-btn">生成视频</button>
                    <button type="button" id="playVideoBtn" class="submit-btn">播放视频</button>
                </div>
            </form>
        </div>
    </div>

    <script>
        (function() {
            const audio = document.getElementById('previewAudio');
            const video = document.getElementById('previewVideo');
            const outputWaveInput = document.getElementById('outputWavePath');
            const outputVideoInput = document.getElementById('outputVideoPath');
            const generateAudioBtn = document.getElementById('generateAudioBtn');
            const generateAudioHuaweiBtn = document.getElementById('generateAudioHuaweiBtn');
            const generateBtn = document.getElementById('generateBtn');
            const playVideoBtn = document.getElementById('playVideoBtn');
            const inputTextEl = document.getElementById('inputText');
            const targetSpeakerEl = document.getElementById('targetSpeaker');
            const referenceAudioPathEl = document.getElementById('referenceAudioPath');

            let speakerProfiles = null;
            let hasGeneratedVideo = false; // becomes true after we set /media/output/result.mp4

            function toMediaUrl(projectRelativePath) {
                // Convert paths like './asset/Obama_1st_15s.wav' or './asset/Obama.mp4' to '/media/asset/...'
                if (!projectRelativePath) return '';
                const trimmed = projectRelativePath.replace(/^\.\//, '');
                if (trimmed.startsWith('asset/')) {
                    return '/media/' + trimmed; // served by /media/asset/<file>
                }
                return projectRelativePath;
            }

            function setAudioSrc(src) {
                if (!src) return;
                audio.src = src;
                audio.load();
            }

            function setVideoSrc(src) {
                if (!src) return;
                video.src = src;
                video.load();
            }

            function setSpeakerPreviewVideo() {
                if (!speakerProfiles) return;
                const key = (targetSpeakerEl.value || '').toLowerCase();
                const profile = speakerProfiles[key];
                if (!profile || !profile.video) return;
                const videoUrl = toMediaUrl(profile.video);
                outputVideoInput.value = videoUrl; // default to speaker preview video
                setVideoSrc(videoUrl);
            }

            function updateReferenceMedia(resetVideo = false) {
                if (!speakerProfiles) return;
                const key = (targetSpeakerEl.value || '').toLowerCase();
                const profile = speakerProfiles[key];
                if (!profile) return;

                if (profile.wav) {
                    const audioUrl = toMediaUrl(profile.wav);
                    referenceAudioPathEl.value = audioUrl;
                    setAudioSrc(audioUrl);
                }
                if (resetVideo) {
                    hasGeneratedVideo = false;
                    setSpeakerPreviewVideo();
                }
            }

            // Load speaker profiles JSON and set initial reference audio/video based on current selection
            fetch('/config/speakers')
                .then(res => res.json())
                .then(data => {
                    speakerProfiles = data || {};
                    // On first load, default to the speaker preview video
                    setSpeakerPreviewVideo();
                    // And set reference audio
                    updateReferenceMedia(false);
                })
                .catch(err => console.error('Failed to load speaker profiles', err));

            // Handlers
            targetSpeakerEl.addEventListener('change', function() { updateReferenceMedia(true); });
            outputVideoInput.addEventListener('change', function() { setVideoSrc(this.value); });
            outputWaveInput.addEventListener('change', function() { setAudioSrc(this.value); });

            // Generate Audio button handler (local TTS)
            generateAudioBtn.addEventListener('click', function() {
                const inputText = (inputTextEl.value || '').trim();
                const targetSpeaker = (targetSpeakerEl.value || '').trim();
                if (!inputText) {
                    alert('请输入要合成的文本');
                    return;
                }
                if (!targetSpeaker) {
                    alert('请选择目标演讲者');
                    return;
                }
                // Call backend to generate audio via TTS
                fetch("{{ url_for('generate') }}", {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                    body: new URLSearchParams({ input_text: inputText, target_speaker: targetSpeaker })
                })
                .then(res => res.json())
                .then(data => {
                    if (data && data.status === 'success' && data.output_path) {
                        // Replace reference audio with generated output
                        outputWaveInput.value = data.output_path;
                        setAudioSrc(data.output_path);
                    } else {
                        alert(data && data.message ? data.message : '音频生成失败');
                    }
                })
                .catch(err => {
                    console.error(err);
                    alert('音频生成失败');
                });
            });

            // Generate Audio button handler (Huawei Cloud TTS via remote API)
            generateAudioHuaweiBtn.addEventListener('click', function() {
                const inputText = (inputTextEl.value || '').trim();
                const targetSpeaker = (targetSpeakerEl.value || '').trim();
                if (!inputText) {
                    alert('请输入要合成的文本');
                    return;
                }
                if (!targetSpeaker) {
                    alert('请选择目标演讲者');
                    return;
                }

                // Collect reference audio and sample_text from profiles
                const key = (targetSpeakerEl.value || '').toLowerCase();
                const profile = speakerProfiles ? speakerProfiles[key] : null;
                const referenceText = profile && profile.sample_text ? profile.sample_text : '';
                const referenceAudioPath = referenceAudioPathEl.value;
                if (!referenceAudioPath) {
                    alert('请先选择参考音频地址');
                    return;
                }

                const params = new URLSearchParams({
                    input_text: inputText,
                    target_speaker: targetSpeaker,
                    reference_audio_path: referenceAudioPath,
                    reference_text: referenceText
                });

                fetch("{{ url_for('generate_huawei') }}", {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                    body: params
                })
                .then(res => res.json())
                .then(data => {
                    if (data && data.status === 'success' && data.output_path) {
                        outputWaveInput.value = data.output_path;
                        audio.src = data.output_path;
                        audio.load();
                    } else {
                        alert(data && data.message ? data.message : '华为云音频生成失败');
                    }
                })
                .catch(err => {
                    console.error(err);
                    alert('华为云音频生成失败');
                });
            });

            // Generate Video button: first extract DeepSpeech features from selected audio
            generateBtn.addEventListener('click', function(e) {
                e.preventDefault();
                const audioPath = (outputWaveInput.value || '').trim();
                if (!audioPath) {
                    alert('请先填写参考音频地址');
                    return;
                }
                fetch('/api/extract_ds_features', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                    body: new URLSearchParams({ audio_path: audioPath })
                })
                .then(res => res.json())
                .then(data => {
                    if (data && data.status === 'success' && data.npy_path) {
                        const speaker = (targetSpeakerEl.value || '').trim().toLowerCase();
                        const npyPath = data.npy_path;
                        return fetch('/api/generate_video', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                            body: new URLSearchParams({ speaker: speaker, npy_path: npyPath })
                        });
                    } else {
                        alert(data && data.message ? data.message : '特征提取失败');
                        throw new Error('extract failed');
                    }
                })
                .then(res => res.json())
                .then(data => {
                    if (data && data.status === 'success' && data.video_path) {
                        // After video generation, always point to /media/output/result.mp4
                        hasGeneratedVideo = true;
                        outputVideoInput.value = data.video_path;
                        setVideoSrc(data.video_path);
                    } else {
                        alert(data && data.message ? data.message : '视频生成失败');
                    }
                })
                .catch(err => {
                    if (err && err.message === 'extract failed') return;
                    console.error(err);
                    alert('视频生成失败');
                });
            });

            // Play Video button: load from outputVideoPath and start playback
            playVideoBtn.addEventListener('click', function() {
                const src = (outputVideoInput.value || '').trim();
                if (!src) { alert('请先填写输出视频地址'); return; }
                setVideoSrc(src);
                // Attempt autoplay; some browsers require user gesture which a click satisfies
                video.play().catch(() => { /* ignore if autoplay blocked */ });
            });
        })();
    </script>
</body>

</html>